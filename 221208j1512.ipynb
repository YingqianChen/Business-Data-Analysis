{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bafc0574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "detail = pd.read_csv('data/detail.csv',\n",
    "    index_col=0,encoding = 'gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7a672f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>dishes_id</th>\n",
       "      <th>logicprn_name</th>\n",
       "      <th>parent_class_name</th>\n",
       "      <th>dishes_name</th>\n",
       "      <th>itemis_add</th>\n",
       "      <th>counts</th>\n",
       "      <th>amounts</th>\n",
       "      <th>cost</th>\n",
       "      <th>place_order_time</th>\n",
       "      <th>discount_amt</th>\n",
       "      <th>discount_reason</th>\n",
       "      <th>kick_back</th>\n",
       "      <th>add_inprice</th>\n",
       "      <th>add_info</th>\n",
       "      <th>bar_code</th>\n",
       "      <th>picture_file</th>\n",
       "      <th>emp_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detail_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>417</td>\n",
       "      <td>610062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>蒜蓉生蚝</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016/8/111:05:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>caipu/104001.jpg</td>\n",
       "      <td>1442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>417</td>\n",
       "      <td>609957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>蒙古烤羊腿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016/8/111:07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>caipu/202003.jpg</td>\n",
       "      <td>1442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>417</td>\n",
       "      <td>609950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>大蒜苋菜</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016/8/111:07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>caipu/303001.jpg</td>\n",
       "      <td>1442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>417</td>\n",
       "      <td>610038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>芝麻烤紫菜</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016/8/111:11:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>caipu/105002.jpg</td>\n",
       "      <td>1442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>417</td>\n",
       "      <td>610003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>蒜香包</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016/8/111:11:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>caipu/503002.jpg</td>\n",
       "      <td>1442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           order_id  dishes_id  logicprn_name  parent_class_name dishes_name  \\\n",
       "detail_id                                                                      \n",
       "2956            417     610062            NaN                NaN        蒜蓉生蚝   \n",
       "2958            417     609957            NaN                NaN       蒙古烤羊腿   \n",
       "2961            417     609950            NaN                NaN        大蒜苋菜   \n",
       "2966            417     610038            NaN                NaN       芝麻烤紫菜   \n",
       "2968            417     610003            NaN                NaN         蒜香包   \n",
       "\n",
       "           itemis_add  counts  amounts  cost  place_order_time  discount_amt  \\\n",
       "detail_id                                                                      \n",
       "2956                0       1       49   NaN  2016/8/111:05:00           NaN   \n",
       "2958                0       1       48   NaN  2016/8/111:07:00           NaN   \n",
       "2961                0       1       30   NaN  2016/8/111:07:00           NaN   \n",
       "2966                0       1       25   NaN  2016/8/111:11:00           NaN   \n",
       "2968                0       1       13   NaN  2016/8/111:11:00           NaN   \n",
       "\n",
       "           discount_reason  kick_back  add_inprice  add_info  bar_code  \\\n",
       "detail_id                                                                \n",
       "2956                   NaN        NaN            0       NaN       NaN   \n",
       "2958                   NaN        NaN            0       NaN       NaN   \n",
       "2961                   NaN        NaN            0       NaN       NaN   \n",
       "2966                   NaN        NaN            0       NaN       NaN   \n",
       "2968                   NaN        NaN            0       NaN       NaN   \n",
       "\n",
       "               picture_file  emp_id  \n",
       "detail_id                            \n",
       "2956       caipu/104001.jpg    1442  \n",
       "2958       caipu/202003.jpg    1442  \n",
       "2961       caipu/303001.jpg    1442  \n",
       "2966       caipu/105002.jpg    1442  \n",
       "2968       caipu/503002.jpg    1442  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d58f4fa1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dishes_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-335781ce3339>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdishes_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dishes_name' is not defined"
     ]
    }
   ],
   "source": [
    "len(dishes_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beabf488",
   "metadata": {},
   "outputs": [],
   "source": [
    "##方法一\n",
    "##定义去重函数\n",
    "def delRep(list1):\n",
    "    list2=[]\n",
    "    for i in list1:\n",
    "        if i not in list2:\n",
    "            list2.append(i)\n",
    "    return list2 \n",
    "## 去重\n",
    "dishes=list(detail['dishes_name']) ##将dishes_name从数据框中提取出来\n",
    "print('去重前菜品总数为：',len(dishes)) \n",
    "dish = delRep(dishes) ##使用自定义的去重函数去重\n",
    "print('方法一去重后菜品总数为：',len(dish))\n",
    "\n",
    "\n",
    "# 代码 5-10\n",
    "##方法二\n",
    "print('去重前菜品总数为：',len(dishes)) \n",
    "dish_set = set(dishes) ##利用set的特性去重\n",
    "print('方法二去重后菜品总数为：',len(dish_set))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593639de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop_duplicates方法去重之后菜品总数为： 145\n"
     ]
    }
   ],
   "source": [
    "# 代码 5-11\n",
    "##对dishes_name去重\n",
    "dishes_name = detail['dishes_name'].drop_duplicates()\n",
    "print('drop_duplicates方法去重之后菜品总数为：',len(dishes_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c410b528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重之前订单详情表的形状为： (10037, 18)\n",
      "依照订单编号，会员编号去重之后订单详情表大小为: (942, 18)\n"
     ]
    }
   ],
   "source": [
    "# 代码 5-12\n",
    "print('去重之前订单详情表的形状为：', detail.shape)\n",
    "shapeDet = detail.drop_duplicates(subset = ['order_id',\n",
    "    'emp_id']).shape\n",
    "print('依照订单编号，会员编号去重之后订单详情表大小为:', shapeDet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66466777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "菜品名称，销量和售价的pearson相似度为：\n",
      "            counts   amounts\n",
      "counts   1.000000 -0.159264\n",
      "amounts -0.159264  1.000000\n"
     ]
    }
   ],
   "source": [
    "# 代码 5-14\n",
    "corrDet1 = detail[['dishes_name','counts',\n",
    "    'amounts']].corr(method='pearson')\n",
    "print('菜品名称，销量和售价的pearson相似度为：\\n',corrDet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376e0525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代码 5-15\n",
    "##定义求取特征是否完全相同的矩阵的函数\n",
    "def FeatureEquals(df):\n",
    "    dfEquals=pd.DataFrame([],columns=df.columns,index=df.columns)\n",
    "    for i in df.columns:\n",
    "       for j in df.columns:\n",
    "           dfEquals.loc[i,j]=df.loc[:,i].equals(df.loc[:,j])\n",
    "    return dfEquals\n",
    "## 应用上述函数\n",
    "detEquals=FeatureEquals(detail)\n",
    "print('detail的特征相等矩阵的前5行5列为：\\n',detEquals.iloc[:5,:5])\n",
    "\n",
    "\n",
    "# 代码 5-16\n",
    "##遍历所有数据\n",
    "lenDet = detEquals.shape[0]\n",
    "dupCol = []\n",
    "for k in range(lenDet):\n",
    "    for l in range(k+1,lenDet):\n",
    "        if detEquals.iloc[k,l] & (detEquals.columns[l] not in dupCol):\n",
    "            dupCol.append(detEquals.columns[l])\n",
    "##进行去重操作\n",
    "print('需要删除的列为：',dupCol)\n",
    "detail.drop(dupCol,axis=1,inplace=True)\n",
    "print('删除多余列后detail的特征数目为：',detail.shape[1])\n",
    "\n",
    "\n",
    "# 代码 5-17\n",
    "print('detail每个特征缺失的数目为：\\n',detail.isnull().sum())\n",
    "print('detail每个特征非缺失的数目为：\\n',detail.notnull().sum())\n",
    "\n",
    "\n",
    "# 代码 5-18\n",
    "print('去除缺失的列前detail的形状为：', detail.shape)\n",
    "print('去除缺失的列后detail的形状为：',\n",
    "    detail.dropna(axis = 1,how ='any').shape)\n",
    "\n",
    "\n",
    "\n",
    "# 代码 5-19\n",
    "detail = detail.fillna(-99)\n",
    "print('detail每个特征缺失的数目为：\\n',detail.isnull().sum())\n",
    "\n",
    "\n",
    "# 代码 5-20\n",
    "## 线性插值\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "x=np.array([1,2,3,4,5,8,9,10]) ##创建自变量x\n",
    "y1=np.array([2,8,18,32,50,128,162,200]) ##创建因变量y1\n",
    "y2=np.array([3,5,7,9,11,17,19,21]) ##创建因变量y2\n",
    "LinearInsValue1 = interp1d(x,y1,kind='linear') ##线性插值拟合x,y1\n",
    "LinearInsValue2 = interp1d(x,y2,kind='linear') ##线性插值拟合x,y2\n",
    "print('当x为6、7时，使用线性插值y1为：',LinearInsValue1([6,7]))\n",
    "print('当x为6、7时，使用线性插值y2为：',LinearInsValue2([6,7]))\n",
    "\n",
    "## 拉格朗日插值\n",
    "from scipy.interpolate import lagrange\n",
    "LargeInsValue1 = lagrange(x,y1) ##拉格朗日插值拟合x,y1\n",
    "LargeInsValue2 = lagrange(x,y2) ##拉格朗日插值拟合x,y2\n",
    "print('当x为6,7时，使用拉格朗日插值y1为：',LargeInsValue1([6,7]))\n",
    "print('当x为6,7时，使用拉格朗日插值y2为：',LargeInsValue2([6,7]))\n",
    "\n",
    "##样条插值\n",
    "from scipy.interpolate import spline\n",
    "##样条插值拟合x,y1\n",
    "SplineInsValue1 = spline(x,y1,xnew=np.array([6,7]))\n",
    "##样条插值拟合x,y2\n",
    "SplineInsValue2 = spline(x,y2,xnew=np.array([6,7]))\n",
    "print('当x为6,7时，使用样条插值y1为：',SplineInsValue1)\n",
    "print('当x为6,7时，使用样条插值y2为：',SplineInsValue2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#######################            任务实现             #######################\n",
    "###############################################################################\n",
    "\n",
    "# 代码 5-23\n",
    "import pandas as pd\n",
    "detail = pd.read_csv('../data/detail.csv',\n",
    "    index_col=0,encoding = 'gbk')\n",
    "print('进行去重操作前订单详情表的形状为：',detail.shape)\n",
    "##样本去重\n",
    "detail.drop_duplicates(inplace = True)\n",
    "##特征去重\n",
    "def FeatureEquals(df):\n",
    "    ##定义求取特征是否完全相同的矩阵的函数\n",
    "    dfEquals=pd.DataFrame([],columns=df.columns,index=df.columns)\n",
    "    for i in df.columns:\n",
    "        for j in df.columns:\n",
    "            dfEquals.loc[i,j]=df.loc[:,i].equals(df.loc[:,j])\n",
    "    return dfEquals\n",
    "detEquals=FeatureEquals(detail)## 应用上述函数\n",
    "##遍历所有数据\n",
    "lenDet = detEquals.shape[0]\n",
    "dupCol = []\n",
    "for k in range(lenDet):\n",
    "    for l in range(k+1,lenDet):\n",
    "        if detEquals.iloc[k,l] & (detEquals.columns[l] not in dupCol):\n",
    "            dupCol.append(detEquals.columns[l])\n",
    "##删除重复列\n",
    "detail.drop(dupCol,axis=1,inplace=True)\n",
    "print('进行去重操作后订单详情表的形状为：',detail.shape)\n",
    "\n",
    "\n",
    "# 代码 5-24\n",
    "##统计各个特征的缺失率\n",
    "naRate = (detail.isnull().sum()/ \\\n",
    "    detail.shape[0]*100).astype('str')+'%'\n",
    "print('detail每个特征缺失的率为：\\n',naRate)\n",
    "##删除全部均为缺失的列\n",
    "detail.dropna(axis = 1,how = 'all',inplace = True)\n",
    "print('经过缺失值处理后订单详情表各特征缺失值的数目为：\\n',\n",
    "    detail.isnull().sum())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68a6b336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用拉依达准则判定异常值个数为: 209\n",
      "异常值的最大值为： 10\n",
      "异常值的最小值为： 3\n"
     ]
    }
   ],
   "source": [
    "# 代码 5-21\n",
    "## 定义拉依达准则识别异常值函数\n",
    "import numpy as np\n",
    "def outRange(Ser1):\n",
    "    boolInd = (Ser1.mean()-3*Ser1.std()>Ser1) | \\\n",
    "    (Ser1.mean()+3*Ser1.var()< Ser1)\n",
    "    index = np.arange(Ser1.shape[0])[boolInd]\n",
    "    outrange = Ser1.iloc[index]\n",
    "    return outrange\n",
    "\n",
    "outlier = outRange(detail['counts'])\n",
    "print('使用拉依达准则判定异常值个数为:',outlier.shape[0])\n",
    "print('异常值的最大值为：',outlier.max())\n",
    "print('异常值的最小值为：',outlier.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdd9d5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAHSCAYAAAAjcvULAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPr0lEQVR4nO3cT6il913H8e/XjqKtFjuTUZJ2JqMgFTKQKHdRMyDSySLEYF2kUKFaJZCFidY/ILqQ6EJwIWIh2QStLVgiMhGUJEhLtBQzNnAnbXCmIwhiZmKiuZ1ZxIVQxJ+L3BmPmTN35nP+zsl9veBw7/Occ57nu7r3fX/Pc0+PMQoAgJv3beseAABg0wgoAICQgAIACAkoAICQgAIACAkoAIDQgVWe7LbbbhvHjh1b5SkBAGZy5syZb44xDk97bqUBdezYsdre3l7lKQEAZtLdr17vOZfwAABCAgoAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAIHTDgOruz3b3m919dmLfwe7+Unf/8+7XDyx3TACAW8fNrEB9rqruf8e+36yqF8YYP1RVL+xuA6zU0aNHq7uvPo4ePbrukYB94oYBNcb4SlVdfsfuj1XV53e//3xV/fRixwLY29GjR+vixYt177331uuvv1733ntvXbx4UUQBKzHrPVDfP8Z4o6pq9+v3LW4kgBu7Ek8vvvhi3X777fXiiy9ejSiAZVv6TeTd/Uh3b3f39s7OzrJPB+wjp06d2nMbYFlmDaj/6O7bq6p2v755vReOMZ4aY2yNMbYOHz484+kArvXQQw/tuQ2wLLMG1F9X1ad2v/9UVf3VYsYBuDlHjhyp06dP14kTJ+qNN96oEydO1OnTp+vIkSPrHg3YBw7c6AXd/XRV/URV3dbdr1XV41X1+1X1F939cFVdqKqPL3NIgHe6cOFCHT16tE6fPl133HFHVb0dVRcuXFjzZMB+cMOAGmP8zHWeOrngWQAiYglYF59EDgAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQElAAACEBBQAQmiuguvtXu/tcd5/t7qe7+zsXNRgAwK1q5oDq7g9W1S9X1dYY43hVvaeqPrGowQBupLuveQCswryX8A5U1Xd194Gqem9VvT7/SAA3NhlLp06dmrofYFkOzPrGMca/dfcfVNWFqvqvqvriGOOLC5sM4CaMMa5+FU/AqsxzCe8DVfWxqvqBqrqjqt7X3Z+c8rpHunu7u7d3dnZmnxTgHSZXnqZtAyxLX/nrLX5j98er6v4xxsO72z9XVR8ZY/zi9d6ztbU1tre3ZzofwKQrq02TP8Om7QOYVXefGWNsTXtunnugLlTVR7r7vf32T62TVXV+juMBxLq7nnnmGZfvgJWaOaDGGC9V1amqermq/nH3WE8taC6APU2uMj300ENT9wMsy8w3kVdVjTEer6rHFzQLQEQsAevik8gBAEICCgAgJKAAAEICCgAgJKAAAEICCgAgJKAAAEICCgAgJKAAAEICCgAgJKAAAEICCgAgJKAAAEICCgAgJKAAAEICCgAgJKAAAEICCgAgJKAAAEICCgAgJKAAAEICCgAgJKAAAEICCgAgJKAAAEICCgAgJKAAAEICCgAgJKAAAEICCgAgJKAAAEICCgAgJKAAAEICCgAgJKAAAEICCthYhw4dqu6++jh06NC6RwL2CQEFbKRDhw7V5cuX66677qpXX3217rrrrrp8+bKIAlbiwLoHAJjFlXg6e/ZsVVWdPXu2jh8/XufOnVvzZMB+YAUK2FjPP//8ntsAyyKggI31wAMP7LkNsCwCCthIBw8erHPnztXx48frwoULVy/fHTx4cN2jAfuAe6CAjXTp0qU6dOhQnTt3ru68886qejuqLl26tObJgP1AQAEbSywB6+ISHgBASEABAIQEFABASEABAIQEFABASEABAIQEFABASEABAIQEFABASEABAIQEFABASEABAIQEFABASEABAIQEFABASEABAIQEFABASEABAIQEFABASEABAIQEFABASEABAIQEFABASEABAIQEFABASEABAIQEFABASEABAIQEFABASEABAIQEFABASEABAIQEFABASEABAIQEFABASEABAITmCqju/t7uPtXd/9Td57v7xxY1GMCNdPc1D4BVmHcF6jNV9TdjjB+uqrur6vz8IwHc2GQsPfroo1P3AyzLgVnf2N3vr6ofr6qfr6oaY3yrqr61mLEAbs4Yo6qqnnjiCfEErMw8K1A/WFU7VfWn3f217v7j7n7fO1/U3Y9093Z3b+/s7MxxOoD/b3Llado2wLL0lb/e4jd2b1XVV6vqxBjjpe7+TFW9Ncb47eu9Z2tra2xvb882KcCEK6tNkz/Dpu0DmFV3nxljbE17bp4VqNeq6rUxxku726eq6kfnOB5ArLvrsccec/kOWKmZA2qM8e9VdbG7P7y762RVfWMhUwHcwOQq05NPPjl1P8CyzHwT+a5fqqovdPd3VNW/VNUvzD8SwM0RS8C6zBVQY4yvV9XUa4MAAO9WPokcACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACB0YN0DAMyqu6/ZN8ZYwyTAfmMFCthIk/H07LPPTt0PsCxWoICNdmXFaYwhnoCVsQIFbKzJladp2wDL0qu8X2Bra2tsb2+v7HzAu9eV1abJn2HT9gHMqrvPjDG2pj1nBQrYaN1dzz33nMt3wEoJKGAjTa4yPfjgg1P3AyyLm8iBjSWWgHWxAgUAEBJQAAAhAQUAEBJQAAAhAQUAEBJQAAAhAQUAEBJQAAAhAQUAEBJQAAAhAQUAEBJQAAAhAQUAEBJQAAAhAQUAEBJQAAAhAQUAEBJQAAAhAQUAEBJQAAAhAQUAEBJQAAAhAQUAEBJQAAAhAQUAEBJQAAAhAQUAEBJQAAAhAQUAEBJQAAAhAQUAEBJQAAAhAQUAEBJQAAAhAQUAEBJQAAChuQOqu9/T3V/r7mcXMRDAzeruax4Aq7CIFahPV9X5BRwH4KZNxtLdd989dT/AshyY583d/aGq+smq+r2q+rWFTAQQGGNc/V48Aasy7wrUH1XVb1TV/1zvBd39SHdvd/f2zs7OnKcD+D+TK0/TtgGWZeaA6u4Hq+rNMcaZvV43xnhqjLE1xtg6fPjwrKcDuMYrr7yy5zbAssyzAnWiqn6qu/+1qv68qj7a3X+2kKkAblJ31z333OPyHbBSMwfUGOO3xhgfGmMcq6pPVNXfjjE+ubDJAPYwee/T5MrT5H6AZZnrJnKAdRJLwLosJKDGGF+uqi8v4lgAALc6n0QOABASUAAAIQEFABASUAAAIQEFABASUAAAIQEFABASUAAAIQEFABASUAAAIQEFABASUAAAIQEFABASUAAAIQEFABASUAAAIQEFABASUAAAIQEFABASUAAAIQEFABASUAAAIQEFABASUAAAIQEFABASUAAAIQEFABASUAAAIQEFABASUAAAIQEFABASUAAAIQEFABASUAAAIQEFABA6sO4BAGbV3dfsG2OsYRJgv7ECBWykyXg6efLk1P0Ay2IFCthokytO4glYFStQwMaaXHmatg2wLAIK2FgvvPDCntsAyyKggI3W3XXfffe5fAeslIACNtLkvU+TK0/+Cw9YBTeRAxtLLAHrYgUKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACAkoAAAQgIKACA0c0B195Hu/rvuPt/d57r704scDADgVnVgjvf+d1X9+hjj5e7+nqo6091fGmN8Y0GzAeypu6/ZN8ZYwyTAfjPzCtQY440xxsu73/9nVZ2vqg8uajCAvUyLp732AyzSPCtQV3X3sar6kap6aRHHA7hZkytO4glYlblvIu/u766qZ6rqV8YYb015/pHu3u7u7Z2dnXlPBwCwdnMFVHd/e70dT18YY/zltNeMMZ4aY2yNMbYOHz48z+kAAG4JM1/C67fXyv+kqs6PMf5wcSMB3DyX7YB1mGcF6kRV/WxVfbS7v777eGBBcwHs6Xr/bee/8IBVmHkFaozx91XlTz9gbcQSsC4+iRwAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAICSgAABCAgoAIHRg3QMAt67uXvgxx+PvX/gxl6V/962FH3OMsfBjAqsnoIDr2u+/7MfvrHsC4FblEh4AQEhAAQCEBBQAQEhAAQCEBBQAQEhAAQCEBBQAQEhAAQCEBBQAQEhAAQCEBBQAQEhAAQCEBBQAQEhAAQCEBBQAQEhAAQCEBBQAQEhAAQCEeoyxupN171TVqys7IbBf3FZV31z3EMC7zp1jjMPTnlhpQAEsQ3dvjzG21j0HsH+4hAcAEBJQAAAhAQW8Gzy17gGA/cU9UAAAIStQAAAhAQVsrO7+bHe/2d1n1z0LsL8IKGCTfa6q7l/3EMD+I6CAjTXG+EpVXV73HMD+I6AAAEICCgAgJKAAAEICCgAgJKCAjdXdT1fVP1TVh7v7te5+eN0zAfuDTyIHAAhZgQIACAkoAICQgAIACAkoAICQgAIACAkoAICQgAIACAkoAIDQ/wLjGF4F0f2v7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "销售量数据异常值个数为： 516\n",
      "销售量数据异常值的最大值为： 10\n",
      "销售量数据异常值的最小值为： 2\n"
     ]
    }
   ],
   "source": [
    "# 代码 5-22\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,8)) \n",
    "p = plt.boxplot(detail['counts'].values,notch=True)   ##画出箱线图\n",
    "outlier1 = p['fliers'][0].get_ydata()   ##fliers为异常值的标签\n",
    "plt.savefig('data/菜品异常数据识别.png')\n",
    "plt.show()\n",
    "print('销售量数据异常值个数为：',len(outlier1))\n",
    "print('销售量数据异常值的最大值为：',max(outlier1))\n",
    "print('销售量数据异常值的最小值为：',min(outlier1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "170523ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "销售量最小值为： 1.0\n",
      "销售量最大值为： 1.0\n",
      "售价最小值为： 1.0\n",
      "售价最大值为： 99.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "# 代码 5-25\n",
    "##定义异常值识别与处理函数\n",
    "def outRange(Ser1):\n",
    "    QL = Ser1.quantile(0.25)\n",
    "    QU = Ser1.quantile(0.75)\n",
    "    IQR = QU-QL\n",
    "    Ser1.loc[Ser1>(QU+1.5*IQR)] = QU\n",
    "    Ser1.loc[Ser1<(QL-1.5*IQR)] = QL\n",
    "    return Ser1\n",
    "## 处理销售量和售价的异常值\n",
    "detail['counts'] = outRange(detail['counts'])\n",
    "detail['amounts'] = outRange(detail['amounts'])\n",
    "##查看处理后的销售量和售价的最小值，最大值\n",
    "print('销售量最小值为：', detail['counts'].min())\n",
    "print('销售量最大值为：', detail['counts'].max())\n",
    "print('售价最小值为：', detail['amounts'].min())\n",
    "print('售价最大值为：', detail['amounts'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eeb1af48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "离差标准化之前销量和售价数据为：\n",
      "            counts  amounts\n",
      "detail_id                 \n",
      "2956          1.0     49.0\n",
      "2958          1.0     48.0\n",
      "2961          1.0     30.0\n",
      "2966          1.0     25.0\n",
      "2968          1.0     13.0\n",
      "离差标准化之后销量和售价数据为：\n",
      "            counts   amounts\n",
      "detail_id                  \n",
      "2956          NaN  0.489796\n",
      "2958          NaN  0.479592\n",
      "2961          NaN  0.295918\n",
      "2966          NaN  0.244898\n",
      "2968          NaN  0.122449\n",
      "标准差标准化之前销量和售价数据为：\n",
      "            counts  amounts\n",
      "detail_id                 \n",
      "2956          1.0     49.0\n",
      "2958          1.0     48.0\n",
      "2961          1.0     30.0\n",
      "2966          1.0     25.0\n",
      "2968          1.0     13.0\n",
      "标准差标准化之后销量和售价数据为：\n",
      "            counts   amounts\n",
      "detail_id                  \n",
      "2956          NaN  0.437491\n",
      "2958          NaN  0.393341\n",
      "2961          NaN -0.401364\n",
      "2966          NaN -0.622116\n",
      "2968          NaN -1.151920\n",
      "小数定标标准化之前的销量和售价数据：\n",
      "            counts  amounts\n",
      "detail_id                 \n",
      "2956          1.0     49.0\n",
      "2958          1.0     48.0\n",
      "2961          1.0     30.0\n",
      "2966          1.0     25.0\n",
      "2968          1.0     13.0\n",
      "小数定标标准化之后的销量和售价数据：\n",
      "            counts  amounts\n",
      "detail_id                 \n",
      "2956          1.0     0.49\n",
      "2958          1.0     0.48\n",
      "2961          1.0     0.30\n",
      "2966          1.0     0.25\n",
      "2968          1.0     0.13\n",
      "标准差标准化之后销量和销量数据为： \n",
      "            counts   amounts\n",
      "detail_id                  \n",
      "2956          NaN  0.437491\n",
      "2958          NaN  0.393341\n",
      "2961          NaN -0.401364\n",
      "2966          NaN -0.622116\n",
      "2968          NaN -1.151920\n",
      "1899          NaN  2.159354\n",
      "1902          NaN  0.702393\n",
      "1906          NaN  2.159354\n",
      "1907          NaN  0.393341\n",
      "1908          NaN -0.313064\n"
     ]
    }
   ],
   "source": [
    "## 自定义离差标准化函数\n",
    "def MinMaxScale(data):\n",
    "    data=(data-data.min())/(data.max()-data.min())\n",
    "    return data\n",
    "##对菜品订单表售价和销量做离差标准化\n",
    "data1=MinMaxScale(detail['counts'])\n",
    "data2=MinMaxScale(detail ['amounts'])\n",
    "data3=pd.concat([data1,data2],axis=1)\n",
    "print('离差标准化之前销量和售价数据为：\\n',\n",
    "    detail[['counts','amounts']].head())\n",
    "print('离差标准化之后销量和售价数据为：\\n',data3.head())\n",
    "\n",
    "\n",
    "\n",
    "# 代码 5-27\n",
    "##自定义标准差标准化函数\n",
    "def StandardScaler(data):\n",
    "    data=(data-data.mean())/data.std()\n",
    "    return data\n",
    "##对菜品订单表售价和销量做标准化\n",
    "data4=StandardScaler(detail['counts'])\n",
    "data5=StandardScaler(detail['amounts'])\n",
    "data6=pd.concat([data4,data5],axis=1)\n",
    "print('标准差标准化之前销量和售价数据为：\\n',\n",
    "    detail[['counts','amounts']].head())\n",
    "print('标准差标准化之后销量和售价数据为：\\n',data6.head())\n",
    "\n",
    "\n",
    "\n",
    "# 代码 5-28\n",
    "##自定义小数定标差标准化函数\n",
    "def DecimalScaler(data):\n",
    "    data=data/10**np.ceil(np.log10(data.abs().max()))\n",
    "    return data\n",
    "##对菜品订单表售价和销量做标准化\n",
    "data7=DecimalScaler(detail['counts'])\n",
    "data8=DecimalScaler(detail['amounts'])\n",
    "data9=pd.concat([data7,data8],axis=1)\n",
    "print('小数定标标准化之前的销量和售价数据：\\n',\n",
    "    detail[['counts','amounts']].head())\n",
    "print('小数定标标准化之后的销量和售价数据：\\n',data9.head())\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#######################            任务实现             #######################\n",
    "###############################################################################\n",
    "\n",
    "# 代码 5-29\n",
    "##自定义标准差标准化函数\n",
    "def StandardScaler(data):\n",
    "    data=(data-data.mean())/data.std()\n",
    "    return data\n",
    "##对菜品订单表售价和销量做标准化\n",
    "data4=StandardScaler(detail['counts'])\n",
    "data5=StandardScaler(detail['amounts'])\n",
    "data6=pd.concat([data4,data5],axis = 1)\n",
    "print('标准差标准化之后销量和销量数据为：','\\n',data6.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad3fb009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "哑变量处理前的数据为：\n",
      " detail_id\n",
      "2956          蒜蓉生蚝\n",
      "2958         蒙古烤羊腿\n",
      "2961          大蒜苋菜\n",
      "2966         芝麻烤紫菜\n",
      "2968           蒜香包\n",
      "           ...    \n",
      "5683          爆炒双丝\n",
      "5686          小炒羊腰\n",
      "5379         香菇鹌鹑蛋\n",
      "5380    不加一滴油的酸奶蛋糕\n",
      "5688          凉拌菠菜\n",
      "Name: dishes_name, Length: 10037, dtype: object\n",
      "哑变量处理后的数据为：\n",
      "            38度剑南春  42度海之蓝  50度古井贡酒  52度泸州老窖  53度茅台  一品香酥藕  三丝鳝鱼  三色凉拌手撕兔  \\\n",
      "detail_id                                                                  \n",
      "2956            0       0        0        0      0      0     0        0   \n",
      "2958            0       0        0        0      0      0     0        0   \n",
      "2961            0       0        0        0      0      0     0        0   \n",
      "2966            0       0        0        0      0      0     0        0   \n",
      "2968            0       0        0        0      0      0     0        0   \n",
      "...           ...     ...      ...      ...    ...    ...   ...      ...   \n",
      "5683            0       0        0        0      0      0     0        0   \n",
      "5686            0       0        0        0      0      0     0        0   \n",
      "5379            0       0        0        0      0      0     0        0   \n",
      "5380            0       0        0        0      0      0     0        0   \n",
      "5688            0       0        0        0      0      0     0        0   \n",
      "\n",
      "           不加一滴油的酸奶蛋糕  五彩藕苗  ...  香辣腐乳炒虾  香酥两吃大虾  鱼香肉丝拌面  鲜美鳝鱼  鸡蛋、肉末肠粉  \\\n",
      "detail_id                    ...                                          \n",
      "2956                0     0  ...       0       0       0     0        0   \n",
      "2958                0     0  ...       0       0       0     0        0   \n",
      "2961                0     0  ...       0       0       0     0        0   \n",
      "2966                0     0  ...       0       0       0     0        0   \n",
      "2968                0     0  ...       0       0       0     0        0   \n",
      "...               ...   ...  ...     ...     ...     ...   ...      ...   \n",
      "5683                0     0  ...       0       0       0     0        0   \n",
      "5686                0     0  ...       0       0       0     0        0   \n",
      "5379                0     0  ...       0       0       0     0        0   \n",
      "5380                1     0  ...       0       0       0     0        0   \n",
      "5688                0     0  ...       0       0       0     0        0   \n",
      "\n",
      "           麻辣小龙虾  黄尾袋鼠西拉子红葡萄酒  黄油曲奇饼干  黄花菜炒木耳  黑米恋上葡萄  \n",
      "detail_id                                              \n",
      "2956           0            0       0       0       0  \n",
      "2958           0            0       0       0       0  \n",
      "2961           0            0       0       0       0  \n",
      "2966           0            0       0       0       0  \n",
      "2968           0            0       0       0       0  \n",
      "...          ...          ...     ...     ...     ...  \n",
      "5683           0            0       0       0       0  \n",
      "5686           0            0       0       0       0  \n",
      "5379           0            0       0       0       0  \n",
      "5380           0            0       0       0       0  \n",
      "5688           0            0       0       0       0  \n",
      "\n",
      "[10037 rows x 145 columns]\n",
      "离散化后5条记录售价分布为：\n",
      " (20.6, 40.2]     3690\n",
      "(40.2, 59.8]     2610\n",
      "(0.902, 20.6]    2454\n",
      "(79.4, 99.0]      722\n",
      "(59.8, 79.4]      561\n",
      "Name: amounts, dtype: int64\n",
      "菜品数据等频法离散化后各个类别数目分布状况为： \n",
      " (39.0, 56.0]    2200\n",
      "(18.0, 32.0]    2107\n",
      "(32.0, 39.0]    1910\n",
      "(1.0, 18.0]     1891\n",
      "(56.0, 99.0]    1743\n",
      "Name: amounts, dtype: int64\n",
      "菜品售价聚类离散化后各个类别数目分布状况为： \n",
      " (21.648, 37.373]    3047\n",
      "(0.0, 21.648]       2454\n",
      "(50.961, 73.993]    2121\n",
      "(37.373, 50.961]    1576\n",
      "(73.993, 99.0]       839\n",
      "Name: amounts, dtype: int64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._maybe_get_bool_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._unpack_bool_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 5",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-b1ab063a3eb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# 代码 5-34\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdetail\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dishes_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'哑变量处理前的数据为：\\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'哑变量处理后的数据为：\\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    887\u001b[0m                     \u001b[1;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m         \u001b[1;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    829\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0msection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m                 \u001b[1;31m# This is an elided recursive call to iloc/loc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 831\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"not applicable\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[1;34m(self, slice_obj, axis)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1136\u001b[1;33m         indexer = labels.slice_indexer(\n\u001b[0m\u001b[0;32m   1137\u001b[0m             \u001b[0mslice_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"loc\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mslice_indexer\u001b[1;34m(self, start, end, step, kind)\u001b[0m\n\u001b[0;32m   5275\u001b[0m         \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5276\u001b[0m         \"\"\"\n\u001b[1;32m-> 5277\u001b[1;33m         \u001b[0mstart_slice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_slice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_locs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5279\u001b[0m         \u001b[1;31m# return a slice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mslice_locs\u001b[1;34m(self, start, end, step, kind)\u001b[0m\n\u001b[0;32m   5480\u001b[0m         \u001b[0mend_slice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5481\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5482\u001b[1;33m             \u001b[0mend_slice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_slice_bound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"right\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5483\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend_slice\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5484\u001b[0m             \u001b[0mend_slice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[1;34m(self, label, side, kind)\u001b[0m\n\u001b[0;32m   5394\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5395\u001b[0m                 \u001b[1;31m# raise the original KeyError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5396\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[1;34m(self, label, side, kind)\u001b[0m\n\u001b[0;32m   5388\u001b[0m         \u001b[1;31m# we need to look up the label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5389\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5390\u001b[1;33m             \u001b[0mslc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5391\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5392\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 5"
     ]
    }
   ],
   "source": [
    "data=detail.loc[:,'dishes_name']   ##抽取部分数据做演示\n",
    "print('哑变量处理前的数据为：\\n',data)\n",
    "print('哑变量处理后的数据为：\\n',pd.get_dummies(data))\n",
    "\n",
    "\n",
    "# 代码 5-31\n",
    "##自定义等宽法离散化函数\n",
    "price = pd.cut(detail['amounts'],5)\n",
    "print('离散化后5条记录售价分布为：\\n' ,price.value_counts())\n",
    "\n",
    "\n",
    "# 代码 5-32\n",
    "##自定义等频法离散化函数\n",
    "def SameRateCut(data,k):\n",
    "    w=data.quantile(np.arange(0,1+1.0/k,1.0/k))\n",
    "    data=pd.cut(data,w)\n",
    "    return data\n",
    "result=SameRateCut(detail['amounts'],5).value_counts()   ##菜品售价等频法离散化\n",
    "print('菜品数据等频法离散化后各个类别数目分布状况为：','\\n',result)\n",
    "\n",
    "\n",
    "# 代码 5-33\n",
    "#自定义数据k-Means聚类离散化函数\n",
    "def KmeanCut(data,k):\n",
    "    from sklearn.cluster import KMeans #引入KMeans\n",
    "    kmodel=KMeans(n_clusters=k)   #建立模型\n",
    "    kmodel.fit(data.values.reshape((len(data), 1)))    #训练模型\n",
    "    c=pd.DataFrame(kmodel.cluster_centers_).sort_values(0)   #输出聚类中心并排序\n",
    "    w=c.rolling(2).mean().iloc[1:]    #相邻两项求中点，作为边界点\n",
    "    w=[0]+list(w[0])+[data.max()]    #把首末边界点加上\n",
    "    data=pd.cut(data,w)\n",
    "    return data\n",
    "#菜品售价等频法离散化\n",
    "result=KmeanCut(detail['amounts'],5).value_counts()\n",
    "print('菜品售价聚类离散化后各个类别数目分布状况为：','\\n',result)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#######################            任务实现             #######################\n",
    "###############################################################################\n",
    "\n",
    "# 代码 5-34\n",
    "data=detail.loc[:5,'dishes_name']\n",
    "print('哑变量处理前的数据为：\\n',data.iloc[:5])\n",
    "print('哑变量处理后的数据为：\\n',pd.get_dummies(data).iloc[:5,:5])\n",
    "\n",
    "\n",
    "# 代码 5-35\n",
    "##自定义等频法离散化函数\n",
    "def SameRateCut(data,k):\n",
    "    w=data.quantile(np.arange(0,1+1.0/k,1.0/k))\n",
    "    data=pd.cut(data,w)\n",
    "    return data\n",
    "result=SameRateCut(detail['amounts'],5).value_counts()   ##菜品售价等频法离散化\n",
    "print('菜品数据等频法离散化后各个类别数目分布状况为：','\\n',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807dd28f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
